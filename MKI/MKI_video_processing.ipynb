{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2daeb2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import mediapipe as mp\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced2515d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_and_select_enter_frames(video_path, num_output_frames=20, end_padding=20, fixed_start_frame=30, yolo_model=None):\n",
    "    if yolo_model is None:\n",
    "        yolo_model = YOLO(\"yolov8m ska visa.pt\")\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    detections = []\n",
    "    frame_idx = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        results = yolo_model.track(frame, persist=True, classes=[0], tracker=\"bytetrack.yaml\", verbose=False)\n",
    "        if results[0].boxes.id is not None:\n",
    "            boxes = results[0].boxes.xyxy.cpu().numpy()\n",
    "            ids = results[0].boxes.id.cpu().numpy()\n",
    "            for box, track_id in zip(boxes, ids):\n",
    "                detections.append({\n",
    "                    \"frame\": frame_idx,\n",
    "                    \"id\": int(track_id),\n",
    "                })\n",
    "        \n",
    "        frame_idx += 1\n",
    "    cap.release()\n",
    "\n",
    "    if not detections:\n",
    "        print(\"No detections found in the video.\")\n",
    "        return []\n",
    "    \n",
    "    id_counts = Counter(d['id'] for d in detections)\n",
    "    main_id = id_counts.most_common(1)[0][0]\n",
    "    track = [d for d in detections if d['id'] == main_id]\n",
    "\n",
    "    start_frame = fixed_start_frame    \n",
    "    last_frame = track[-1][\"frame\"]\n",
    "    end_frame = min(last_frame + end_padding, total_frames - 1)\n",
    "\n",
    "    if end_frame <= start_frame:\n",
    "        print(\"trimmed range is invalid.\")\n",
    "        return []\n",
    "    \n",
    "    selected_frames = np.linspace(start_frame, end_frame, num_output_frames, dtype=int).tolist()\n",
    "\n",
    "    return selected_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bbd426d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_and_select_pass_frames(\n",
    "        video_path, \n",
    "        num_output_frames=20, \n",
    "        end_padding=40, \n",
    "        fixed_start_frame=30,\n",
    "        yolo_model=None,\n",
    "        stop_window=30,\n",
    "        horizontal_thresh=5):\n",
    "    \n",
    "    if yolo_model is None:\n",
    "        yolo_model = YOLO(\"yolov8l.pt\")\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    frame_idx = 0\n",
    "    track_history = defaultdict(list)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        results = yolo_model.track(frame, persist=True, classes=[0], tracker=\"bytetrack.yaml\", verbose=False)\n",
    "        \n",
    "        if results[0].boxes.id is not None:\n",
    "            boxes = results[0].boxes.xyxy.cpu().numpy()\n",
    "            ids = results[0].boxes.id.cpu().numpy()\n",
    "            for box, track_id in zip(boxes, ids):\n",
    "                x1, y1, x2, y2 = box\n",
    "                center_x = (x1 + x2) / 2\n",
    "                track_history[int(track_id)].append((frame_idx, center_x))\n",
    "        frame_idx += 1\n",
    "    \n",
    "    cap.release()\n",
    "\n",
    "    if not track_history:\n",
    "        print(\"No significant motion detected in the video.\")\n",
    "        return []\n",
    "    \n",
    "    main_id = max(track_history, key=lambda k: len(track_history[k]))\n",
    "    main_track = track_history[main_id]\n",
    "\n",
    "    main_track.sort()\n",
    "\n",
    "    for i in range(len(main_track) -stop_window -1, 0, -1):\n",
    "        recent_positions = [x for _, x in main_track[i:i+stop_window]]\n",
    "        max_disp = max(recent_positions) - min(recent_positions)\n",
    "        if max_disp > horizontal_thresh:\n",
    "            stop_frame = main_track[i + stop_window][0]\n",
    "            break\n",
    "    else:\n",
    "        stop_frame = main_track[-1][0]\n",
    "    \n",
    "    \n",
    "    start_frame = fixed_start_frame\n",
    "    end_frame = min(stop_frame - end_padding, total_frames - 1)\n",
    "\n",
    "    if end_frame <= start_frame:\n",
    "        print(\"trimmed range is invalid.\")\n",
    "        return []\n",
    "    \n",
    "    selected_frames = np.linspace(start_frame, end_frame, num_output_frames, dtype=int).tolist()\n",
    "    return selected_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "078f77c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_trimmed_video(video_path, selected_frames, output_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error opening video file: {video_path}\")\n",
    "        return\n",
    "    \n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "    selected_set = set(selected_frames)\n",
    "    frame_idx = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_idx in selected_set:\n",
    "            out.write(frame)\n",
    "        frame_idx += 1\n",
    "    \n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(f\"Trimmed video saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bbf09133",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_videos(input_dir, output_dir, yolo_small_model, yolo_large_model):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for folder_name in os.listdir(input_dir):\n",
    "        folder_path = os.patj.join(input_dir, folder_name)\n",
    "        if not os.path.isdir(folder_path):\n",
    "            continue\n",
    "\n",
    "        for filename in os.listdir(folder_path):\n",
    "            if not filename.lower().endswith(('.mp4', '.avi', '.mov')):\n",
    "                continue\n",
    "\n",
    "            video_path = os.path .join(folder_path, filename)\n",
    "\n",
    "            if \"enter\" in folder_name.lower():\n",
    "                selected_frames = trim_and_select_enter_frames(\n",
    "                    video_path,\n",
    "                    num_output_frames=20,\n",
    "                    end_padding=20,\n",
    "                    fixed_start_frame=30,\n",
    "                    yolo_model=yolo_small_model)\n",
    "                subfolder = \"processed_enter\"\n",
    "\n",
    "            elif \"pass\" in folder_name.lower():\n",
    "                selected_frames = trim_and_select_pass_frames(\n",
    "                    video_path,\n",
    "                    num_output_frames=20,\n",
    "                    end_padding=40,\n",
    "                    fixed_start_frame=30,\n",
    "                    yolo_model=yolo_large_model,\n",
    "                    stop_window=30,\n",
    "                    horizontal_thresh=5)\n",
    "                subfolder = \"processed_pass\"\n",
    "            else:\n",
    "                print(f\"Skipping {filename}, unknown label\")\n",
    "                continue\n",
    "\n",
    "            if not selected_frames:\n",
    "                print(f\"No valid frames selected for {filename}.\")\n",
    "                continue\n",
    "\n",
    "            output_folder = os.path.join(output_dir, subfolder)\n",
    "            os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "            base_name, ext = os.path.splitext(filename)\n",
    "            output_path = os.path.join(output_folder, f\"{base_name}_trimmed{ext}\")\n",
    "\n",
    "            save_trimmed_video(video_path, selected_frames, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c1fc98c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_frames = trim_and_select_pass_frames(\"C:/Users/hanna/Documents/Thesis/datainsamling/data/SLOW_front_pass/front_pass_2.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ed802e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_frame(video_path, frame_number):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(f\"Could not read frame {frame_number}\")\n",
    "        return\n",
    "\n",
    "    cv2.imshow(f\"Frame {frame_number}\", frame)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2adc6bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame in selected_frames:\n",
    "    show_frame(\"C:/Users/hanna/Documents/Thesis/datainsamling/data/SLOW_front_pass/front_pass_2.mp4\", frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13cf58b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_save_frame(video_path, selected_frames, save_dir):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_idx = 0\n",
    "    selected_set = set(selected_frames)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_idx in selected_set:\n",
    "            filename = os.path.join(save_dir, f\"frame_{frame_idx:04d}.jpg\")\n",
    "            cv2.imwrite(filename, frame)\n",
    "\n",
    "        frame_idx += 1\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca4f724",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
